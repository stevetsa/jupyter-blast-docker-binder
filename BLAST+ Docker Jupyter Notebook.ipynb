{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains documentation for the NCBI BLAST+ command line applications using a Docker image with BLAST+ and Jupyter Notebook server installed. We will demonstrate how to run BLAST analysis on the Google Cloud Platform using a small basic example and a more advanced production-level example. Some basic knowledge of Unix/Linux commands and BLAST+ is useful in completing this tutorial.  \n",
    "\n",
    "In this section, We will first use the same small example from Section 1 of the official BLAST+ Docker [repository.](https://github.com/ncbi/blast_plus_docs)\n",
    "\n",
    "Input data\n",
    "* Query – 1 sequence, 44 nucleotides, file size 0.2 KB\n",
    "* Database – 7 sequences, 922 nucleotides, file size 1.7 KB\n",
    "\n",
    "### System Configurations\n",
    "Region us-east4 (Northern Virginia)   \n",
    "Zone us-east4c   \n",
    "16vCPU 104 GB Memory n1-highmem-16   \n",
    "New 200 GB standard persistent disk  \n",
    "Ubuntu 18.04 LTS  \n",
    "\n",
    "### GCP VM Cost Estimate (June 2019 - provided by GCP when VM is created)\n",
    "559.96 dollars monthly ($0.767 hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run BLAST+ Using a Small Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastn: 2.9.0+\n",
      " Package: blast 2.9.0, build Jun 10 2019 16:40:23\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "!blastn -version\n",
    "!efetch -version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BLAST+ in current directory\n",
    "!mkdir -p blastdb queries fasta results blastdb_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sequences\n",
    "!efetch -db protein -format fasta -id P01349 > queries/P01349.fsa\n",
    "!efetch -db protein -format fasta -id Q90523,P80049,P83981,P83982,P83983,P83977,P83984,P83985,P27950 > fasta/nurse-shark-proteins.fsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mylagimail2011/jupyter_folder/blastdb_custom\n",
      "\n",
      "\n",
      "Building a new DB, current time: 06/12/2019 21:33:35\n",
      "New DB name:   /home/mylagimail2011/jupyter_folder/blastdb_custom/nurse-shark-proteins\n",
      "New DB title:  Nurse shark proteins\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 7 sequences in 0.0144598 seconds.\n",
      "/home/mylagimail2011/jupyter_folder\n",
      "BLASTP 2.9.0+\n",
      "\n",
      "\n",
      "Reference: Stephen F. Altschul, Thomas L. Madden, Alejandro A.\n",
      "Schaffer, Jinghui Zhang, Zheng Zhang, Webb Miller, and David J.\n",
      "Lipman (1997), \"Gapped BLAST and PSI-BLAST: a new generation of\n",
      "protein database search programs\", Nucleic Acids Res. 25:3389-3402.\n",
      "\n",
      "\n",
      "Reference for composition-based statistics: Alejandro A. Schaffer,\n",
      "L. Aravind, Thomas L. Madden, Sergei Shavirin, John L. Spouge, Yuri\n",
      "I. Wolf, Eugene V. Koonin, and Stephen F. Altschul (2001),\n",
      "\"Improving the accuracy of PSI-BLAST protein database searches with\n",
      "composition-based statistics and other refinements\", Nucleic Acids\n",
      "Res. 29:2994-3005.\n",
      "\n",
      "\n",
      "\n",
      "Database: Nurse shark proteins\n",
      "           7 sequences; 922 total letters\n",
      "\n",
      "\n",
      "\n",
      "Query= sp|P01349.2|RELX_CARTA RecName: Full=Relaxin; Contains: RecName:\n",
      "Full=Relaxin B chain; Contains: RecName: Full=Relaxin A chain\n",
      "\n",
      "Length=44\n",
      "                                                                      Score        E\n",
      "Sequences producing significant alignments:                          (Bits)     Value\n",
      "\n",
      "P80049.1 RecName: Full=Fatty acid-binding protein, liver; AltName...  14.2       0.96 \n",
      "\n",
      "\n",
      ">P80049.1 RecName: Full=Fatty acid-binding protein, liver; AltName: Full=Liver-type \n",
      "fatty acid-binding protein; Short=L-FABP\n",
      "Length=132\n",
      "\n",
      " Score = 14.2 bits (25),  Expect = 0.96, Method: Compositional matrix adjust.\n",
      " Identities = 3/9 (33%), Positives = 6/9 (67%), Gaps = 0/9 (0%)\n",
      "\n",
      "Query  2    LCGRGFIRA  10\n",
      "            +C R ++R \n",
      "Sbjct  123  VCTREYVRE  131\n",
      "\n",
      "\n",
      "\n",
      "Lambda      K        H        a         alpha\n",
      "   0.334    0.143    0.520    0.792     4.96 \n",
      "\n",
      "Gapped\n",
      "Lambda      K        H        a         alpha    sigma\n",
      "   0.267   0.0410    0.140     1.90     42.6     43.6 \n",
      "\n",
      "Effective search space used: 22680\n",
      "\n",
      "\n",
      "  Database: Nurse shark proteins\n",
      "    Posted date:  Jun 12, 2019  9:33 PM\n",
      "  Number of letters in database: 922\n",
      "  Number of sequences in database:  7\n",
      "\n",
      "\n",
      "\n",
      "Matrix: BLOSUM62\n",
      "Gap Penalties: Existence: 11, Extension: 1\n",
      "Neighboring words threshold: 11\n",
      "Window for multiple hits: 40\n"
     ]
    }
   ],
   "source": [
    "# Create BLAST databases and run BLAST\n",
    "%cd blastdb_custom\n",
    "!makeblastdb -in ../fasta/nurse-shark-proteins.fsa -dbtype prot -parse_seqids -out nurse-shark-proteins -title \"Nurse shark proteins\" -taxid 7801 -blastdb_version 5\n",
    "%cd ..\n",
    "!blastp -query queries/P01349.fsa -db blastdb_custom/nurse-shark-proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run BLAST+ at Production Scale\n",
    "One of the promises of cloud computing is scalability. In this section, we will demonstrate how to use the BLAST+ Docker image at production scale on the Google Cloud Platform. We will perform a BLAST analysis similar to the approach described in this publication to compare de novo aligned contigs from bacterial 16S-23S sequencing against the nucleotide collection (nt) database.\n",
    "\n",
    "To test scalability, we will use inputs of different sizes to estimate the amount of time to download the nucleotide collection database and run BLAST search using the latest version of the BLAST+ Docker image. Expected results are summarized in the following tables.\n",
    "\n",
    "Input files: 28 samples (multi-FASTA files) containing de novo aligned contigs from the publication.\n",
    "(Instructions to download and create the input files are described in the code block below.)\n",
    "\n",
    "Database: Pre-formatted BLAST nucleotide collection database, version 5 (nt_v5): 68.7217 GB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This section assumes using recommended hardware requirements - 16 CPUs, 104 GB memory and 200 GB persistent hard disk.\n",
    "Modify the number of CPUs (-num_threads) if another type of VM is used.\n",
    "\n",
    "#### Step 1. Prepare for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create directories, if not already done\n",
    "!mkdir -p blastdb queries fasta results blastdb_custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-12 21:36:24--  https://ndownloader.figshare.com/articles/6865397?private_link=729b346eda670e9daba4\n",
      "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 18.202.190.34, 176.34.151.132, 52.30.75.146, ...\n",
      "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|18.202.190.34|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2327955 (2.2M) [application/zip]\n",
      "Saving to: ‘fa.zip’\n",
      "\n",
      "fa.zip              100%[===================>]   2.22M   798KB/s    in 2.8s    \n",
      "\n",
      "2019-06-12 21:36:27 (798 KB/s) - ‘fa.zip’ saved [2327955/2327955]\n",
      "\n",
      "Archive:  fa.zip\n",
      " extracting: fa/Sample_13 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_14 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_15 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_16 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_17 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_18 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_19 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_20 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_21 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_22 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_23 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_24 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_25 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_26 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_27 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_28 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Negative control (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Positive control (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_1 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_2 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_3 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_4 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_5 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_6 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_7 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_8 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_9 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_10 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_11 (paired) trimmed (paired) assembly.fa  \n",
      " extracting: fa/Sample_12 (paired) trimmed (paired) assembly.fa  \n"
     ]
    }
   ],
   "source": [
    "## Import and process input sequences\n",
    "\n",
    "!wget https://ndownloader.figshare.com/articles/6865397?private_link=729b346eda670e9daba4 -O fa.zip\n",
    "!unzip fa.zip -d fa\n",
    "### Create three input query files\n",
    "### All 28 samples\n",
    "!cat fa/*.fa > query.fa\n",
    "\n",
    "### Sample 1\n",
    "!cat fa/'Sample_1 (paired) trimmed (paired) assembly.fa' > query1.fa\n",
    "\n",
    "### Sample 1 to Sample 5\n",
    "!cat fa/'Sample_1 (paired) trimmed (paired) assembly.fa' \\\n",
    "    fa/'Sample_2 (paired) trimmed (paired) assembly.fa' \\\n",
    "    fa/'Sample_3 (paired) trimmed (paired) assembly.fa' \\\n",
    "    fa/'Sample_4 (paired) trimmed (paired) assembly.fa' \\\n",
    "    fa/'Sample_5 (paired) trimmed (paired) assembly.fa' > query5.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copy query sequences to $HOME/queries folder\n",
    "!cp query* queries/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to GCP\r\n",
      "BLASTDB                                                      DESCRIPTION                                                                                                              SIZE (GB)      LAST_UPDATED\r\n",
      "GPIPE/10090/106/GCF_000001635.24_top_level                   Mus musculus GRCm38.p4 [GCF_000001635.24] chromosomes plus unplaced and unlocalized scaffolds                               1.4707      2016-06-22\r\n",
      "GPIPE/9606/109/GCF_000001405.38_top_level                    Homo sapiens GRCh38.p12 [GCF_000001405.38] chromosomes plus unplaced and unlocalized scaffolds                              1.7225      2018-03-28\r\n",
      "SMARTBLAST/landmark_v5                                       Landmark database for SmartBLAST                                                                                            0.5262      2019-03-19\r\n",
      "genomic/Viruses/NCBI_VIV_nucleotide_sequences_v5             NCBI VIV nucleotide sequences                                                                                              71.3578      2019-06-11\r\n",
      "genomic/Viruses/NCBI_VIV_protein_sequences_v5                NCBI VIV protein sequences                                                                                                236.2467      2019-06-11\r\n",
      "nr_v5                                                        All non-redundant GenBank CDS translations+PDB+SwissProt+PIR+PRF excluding environmental samples from WGS projects        236.2419      2019-05-23\r\n",
      "nt_v5                                                        Nucleotide collection (nt)                                                                                                 71.3569      2019-05-23\r\n",
      "pdb_v5                                                       PDB protein database                                                                                                        0.2950      2019-06-11\r\n",
      "rRNA_typestrains/prokaryotic_16S_ribosomal_RNA_v5            16S ribosomal RNA (Bacteria and Archaea)                                                                                   71.3570      2019-06-11\r\n",
      "ref_viroids_rep_genomes_v5                                   Refseq viroids representative genomes                                                                                       0.1558      2019-05-21\r\n",
      "ref_viruses_rep_genomes_v5                                   Refseq viruses representative genomes                                                                                       0.2351      2019-05-21\r\n",
      "refseq_protein_v5                                            NCBI Protein Reference Sequences                                                                                          236.2673      2019-06-11\r\n",
      "refseq_rna_v5                                                NCBI Transcript Reference Sequences                                                                                        71.3634      2019-06-11\r\n",
      "split-cdd                                                    CDD split into 32 volumes                                                                                                   5.7475      2019-06-11\r\n",
      "swissprot_v5                                                 Non-redundant UniProtKB/SwissProt sequences                                                                                 0.5143      2019-06-11\r\n",
      "taxdb                                                        Taxonomy BLAST databases                                                                                                    0.1557      2019-06-10\r\n"
     ]
    }
   ],
   "source": [
    "## Step 2. Display BLAST databases on the GCP\n",
    "!update_blastdb.pl --showall pretty --source gcp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'blastdb'\n",
      "/home/mylagimail2011/jupyter_folder/blastdb\n",
      "Connected to GCP\n",
      "/home/mylagimail2011/jupyter_folder\n"
     ]
    }
   ],
   "source": [
    "## Download nt_v5 (nucleotide collection version 5) database\n",
    "## This step takes approximately 9 min.  Background processes not supported\n",
    "%cd blastdb\n",
    "!update_blastdb.pl --source gcp nt_v5 \n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, confirm query/database have been properly provisioned before proceeding.  \n",
    "First, check the size of the directory containing the BLAST database\n",
    "(nt_v5 should be around 68 GB) In addition, there should be three files in the `queries` folder - `query.fa`, `query1.fa`, and `query5.fa`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69162420\tblastdb\n",
      "total 2756\n",
      "drwxr-xr-x 2 jovyan users    4096 Jun 12 21:37 .\n",
      "drwxrwxrwx 9   1001  1002    4096 Jun 12 21:46 ..\n",
      "-rw-r--r-- 1 jovyan users     173 Jun 12 21:33 P01349.fsa\n",
      "-rw-r--r-- 1 jovyan users   58804 Jun 12 21:37 query1.fa\n",
      "-rw-r--r-- 1 jovyan users  422279 Jun 12 21:37 query5.fa\n",
      "-rw-r--r-- 1 jovyan users 2321683 Jun 12 21:37 query.fa\n"
     ]
    }
   ],
   "source": [
    "!du -sk blastdb\n",
    "!ls -al queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Run BLAST\n",
    "\n",
    "First, run BLAST using `query1.fa`. (Sample 1) \n",
    "This command will take approximately 8 minutes to complete and create a 3.1 GB output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\r\n"
     ]
    }
   ],
   "source": [
    "!blastn -query queries/query1.fa -db blastdb/nt_v5 -num_threads 16 -out results/blastn.query1.denovo16s.out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run BLAST using query5.fa (Samples 1-5) \n",
    "This command will take approximately 27 minutes to complete and create a 10.4 GB output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!blastn -query queries/query5.fa -db blastdb/nt_v5 -num_threads 16 -out results/blastn.query5.denovo16s.out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run BLAST using `query.fa` (All samples) This command will take approximately 140 minutes to complete and create a 47.8 GB output file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!blastn -query queries/query.fa -db blastdb/nt_v5 -num_threads 16 -out results/blastn.query.denovo16s.out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the GCP instance\n",
    "Remember to stop or delete the VM to prevent incurring additional cost. You can do this at the GCP Console.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
